{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OD-trial-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHwuqkg+IuF7NURTFiw03p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Object-Detection/blob/main/OD_trial_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui_iggkRKSbT",
        "outputId": "e9e35e0e-2da9-45b7-b59f-f86db6f5f0ea"
      },
      "source": [
        "!git clone https://github.com/pytorch/vision.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 39419, done.\u001b[K\n",
            "remote: Counting objects: 100% (4915/4915), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1369/1369), done.\u001b[K\n",
            "remote: Total 39419 (delta 3801), reused 4435 (delta 3438), pack-reused 34504\u001b[K\n",
            "Receiving objects: 100% (39419/39419), 52.41 MiB | 3.90 MiB/s, done.\n",
            "Resolving deltas: 100% (30328/30328), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kIl3KBQMJz1",
        "outputId": "ffdb0804-114a-4fc7-b950-1a468e6e715e"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'tv-training-code.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yzl4P3cMW7N",
        "outputId": "c945102a-30df-4223-dfc1-807143eac225"
      },
      "source": [
        "!wget -O data.zip \"https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 09:07:32--  https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\n",
            "Resolving www.cis.upenn.edu (www.cis.upenn.edu)... 158.130.69.163, 2607:f470:8:64:5ea5::d\n",
            "Connecting to www.cis.upenn.edu (www.cis.upenn.edu)|158.130.69.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53723336 (51M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  51.23M  13.6MB/s    in 4.8s    \n",
            "\n",
            "2021-09-25 09:07:38 (10.6 MB/s) - ‘data.zip’ saved [53723336/53723336]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3jVfIN8M0-R"
      },
      "source": [
        "!unzip -q data.zip"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6seiG_seM7k2",
        "outputId": "f7db4b55-a881-4b4a-9e14-a9791114ece0"
      },
      "source": [
        "ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.zip  \u001b[0m\u001b[01;34mPennFudanPed\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mvision\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N9pW1XvNPv1"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMQUuB5qJLbs",
        "outputId": "88b1e6be-486d-4284-fa45-7924865f7130"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'vision/references/detection/tv-training-code.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnalpAmIJRUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b811b5db-78f1-4975-c482-3e546465a508"
      },
      "source": [
        "!wget \"https://pytorch.org/tutorials/_static/tv-training-code.py\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 09:11:48--  https://pytorch.org/tutorials/_static/tv-training-code.py\n",
            "Resolving pytorch.org (pytorch.org)... 185.199.108.153\n",
            "Connecting to pytorch.org (pytorch.org)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6003 (5.9K) [application/octet-stream]\n",
            "Saving to: ‘tv-training-code.py.1’\n",
            "\n",
            "\rtv-training-code.py   0%[                    ]       0  --.-KB/s               \rtv-training-code.py 100%[===================>]   5.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-25 09:11:48 (33.5 MB/s) - ‘tv-training-code.py.1’ saved [6003/6003]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s6yPGxXOFcD"
      },
      "source": [
        "mv tv-training-code.py vision/references/detection/"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUFKeDh8OH5J",
        "outputId": "d2a2dfc7-ba4b-4f9d-b0eb-7ab0a259ceff"
      },
      "source": [
        "!python vision/references/detection/tv-training-code.py"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n",
            "100% 170M/170M [00:02<00:00, 65.2MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"vision/references/detection/tv-training-code.py\", line 165, in <module>\n",
            "    main()\n",
            "  File \"vision/references/detection/tv-training-code.py\", line 156, in main\n",
            "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
            "  File \"/content/vision/references/detection/engine.py\", line 24, in train_one_epoch\n",
            "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=warmup_factor,\n",
            "AttributeError: module 'torch.optim.lr_scheduler' has no attribute 'LinearLR'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41uIB3SCOb5I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}