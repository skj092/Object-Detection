{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skj092/Object-Detection/blob/main/notebooks/TFOD2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98rds-2OU-Rd"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1c95xMGcU5_Z"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1UUX8SUUiMO"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf2_object_detection\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/tensorflow/collections/object_detection/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# TensorFlow Hub Object Detection Colab\n",
        "\n",
        "Welcome to the TensorFlow Hub Object Detection Colab! This notebook will take you through the steps of running an \"out-of-the-box\" object detection model on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRImnk_7WOq1"
      },
      "source": [
        "### More models\n",
        "[This](https://tfhub.dev/tensorflow/collections/object_detection/1) collection contains TF2 object detection models that have been trained on the COCO 2017 dataset. [Here](https://tfhub.dev/s?module-type=image-object-detection) you can find all object detection models that are currently hosted on [tfhub.dev](https://tfhub.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Imports and Setup\n",
        "\n",
        "Let's start with the base imports."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle \n",
        "!pip install -q kaggle-cli"
      ],
      "metadata": {
        "id": "VnRDvCwilvee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = 'sonujha090'\n",
        "os.environ['KAGGLE_KEY'] = \"************************\""
      ],
      "metadata": {
        "id": "wbkS7aSJleKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d mbkinaci/fruit-images-for-object-detection "
      ],
      "metadata": {
        "id": "gBdamxKpmSbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/fruit-images-for-object-detection.zip"
      ],
      "metadata": {
        "id": "JcA-ho-tnH-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk4FU-jx9kc3"
      },
      "outputs": [],
      "source": [
        "# # This Colab requires TF 2.5.\n",
        "# !pip install -U \"tensorflow>=2.5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn5_uV1HLvaz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "# Clone the tensorflow models repository\n",
        "git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "Jgh3dQuX6cAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up the directory structure**"
      ],
      "metadata": {
        "id": "9ngRNZ3a8te0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "mkdir TensorFlow\n",
        "\n",
        "mkdir TensorFlow/workspace\n",
        "\n",
        "mkdir TensorFlow/script\n",
        "\n",
        "mkdir TensorFlow/script/preprocessing\n",
        "\n",
        "mkdir TensorFlow/workspace/training_demo\n",
        "\n",
        "mkdir TensorFlow/workspace/training_demo/annotations/\n",
        "\n",
        "mkdir TensorFlow/workspace/training_demo/exported-models\n",
        "\n",
        "mkdir TensorFlow/workspace/training_demo/images\n",
        "\n",
        "mkdir TensorFlow/workspace/training_demo/models\n",
        "\n",
        "mkdir TensorFlow/workspace/training_demo/pre-trained-models\n",
        "\n",
        "mv models TensorFlow/\n",
        "\n",
        "mv train_zip/train /content/TensorFlow/workspace/training_demo/images\n",
        "\n",
        "mv test_zip/test /content/TensorFlow/workspace/training_demo/images"
      ],
      "metadata": {
        "id": "dAP7qeFW4im6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/TensorFlow/models/research/object_detection/data/mscoco_label_map.pbtxt /content/TensorFlow/workspace/training_demo/annotations/"
      ],
      "metadata": {
        "id": "O7q7xryf4rz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uodate mscoco_label_map.pbtxt\n",
        "\n",
        "\n",
        "label_map_str = \"\"\"item {\n",
        "    id: 1\n",
        "    name: 'apple'\n",
        "}\n",
        "\n",
        "item {\n",
        "    id: 2\n",
        "    name: 'banana'\n",
        "}\n",
        "\n",
        "item {\n",
        "    id: 3\n",
        "    name: 'orange'\n",
        "}\"\"\"\n",
        "\n",
        "with open('/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt', 'w') as f:\n",
        "  f.write(label_map_str)\n",
        "\n",
        "!more /content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt"
      ],
      "metadata": {
        "id": "hwg1TcO0-YFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd /content/TensorFlow/models/research\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "vF4z5g--D3hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "FNYJTnbQD_M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "wget \"https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py\" \n",
        "\n"
      ],
      "metadata": {
        "id": "wjFwBpaX4rmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mv generate_tfrecord.py /content/TensorFlow/script/preprocessing"
      ],
      "metadata": {
        "id": "Whl8GQftbjoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TensorFlow/script/preprocessing"
      ],
      "metadata": {
        "id": "RZFr3DdDbQQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_tfrecord.py -x /content/TensorFlow/workspace/training_demo/images/train -l /content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt -o /content/TensorFlow/workspace/training_demo/annotations/train.record\n"
      ],
      "metadata": {
        "id": "hUz4WecLbN4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_tfrecord.py -x /content/TensorFlow/workspace/training_demo/images/test -l /content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt -o /content/TensorFlow/workspace/training_demo/annotations/test.record"
      ],
      "metadata": {
        "id": "L8VYVYgybOcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\""
      ],
      "metadata": {
        "id": "yFmBb8XGOJYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz"
      ],
      "metadata": {
        "id": "6yiJjedPOJRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8 /content/TensorFlow/workspace/training_demo/pre-trained-models"
      ],
      "metadata": {
        "id": "ni8XaYWnOJLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/"
      ],
      "metadata": {
        "id": "AhhSMiu9_Lc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/TensorFlow/workspace/training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config /content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/"
      ],
      "metadata": {
        "id": "MW2MZ8laOJFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import Template\n",
        "\n",
        "config_file_template =  \"\"\"model {\n",
        "  ssd {\n",
        "    num_classes: 3\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 640\n",
        "        width: 640\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: \"ssd_resnet50_v1_fpn_keras\"\n",
        "      depth_multiplier: 1.0\n",
        "      min_depth: 16\n",
        "      conv_hyperparams {\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00039999998989515007\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            mean: 0.0\n",
        "            stddev: 0.029999999329447746\n",
        "          }\n",
        "        }\n",
        "        activation: RELU_6\n",
        "        batch_norm {\n",
        "          decay: 0.996999979019165\n",
        "          scale: true\n",
        "          epsilon: 0.0010000000474974513\n",
        "        }\n",
        "      }\n",
        "      override_base_feature_extractor_hyperparams: true\n",
        "      fpn {\n",
        "        min_level: 3\n",
        "        max_level: 7\n",
        "      }\n",
        "    }\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "        use_matmul_gather: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      weight_shared_convolutional_box_predictor {\n",
        "        conv_hyperparams {\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00039999998989515007\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            random_normal_initializer {\n",
        "              mean: 0.0\n",
        "              stddev: 0.009999999776482582\n",
        "            }\n",
        "          }\n",
        "          activation: RELU_6\n",
        "          batch_norm {\n",
        "            decay: 0.996999979019165\n",
        "            scale: true\n",
        "            epsilon: 0.0010000000474974513\n",
        "          }\n",
        "        }\n",
        "        depth: 256\n",
        "        num_layers_before_predictor: 4\n",
        "        kernel_size: 3\n",
        "        class_prediction_bias_init: -4.599999904632568\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      multiscale_anchor_generator {\n",
        "        min_level: 3\n",
        "        max_level: 7\n",
        "        anchor_scale: 4.0\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        scales_per_octave: 2\n",
        "      }\n",
        "    }\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 9.99999993922529e-09\n",
        "        iou_threshold: 0.6000000238418579\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "        use_static_shapes: false\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    loss {\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      classification_loss {\n",
        "        weighted_sigmoid_focal {\n",
        "          gamma: 2.0\n",
        "          alpha: 0.25\n",
        "        }\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    encode_background_as_zeros: true\n",
        "    normalize_loc_loss_by_codesize: true\n",
        "    inplace_batchnorm_update: true\n",
        "    freeze_batchnorm: false\n",
        "  }\n",
        "}\n",
        "train_config {\n",
        "  batch_size: 8\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_crop_image {\n",
        "      min_object_covered: 0.0\n",
        "      min_aspect_ratio: 0.75\n",
        "      max_aspect_ratio: 3.0\n",
        "      min_area: 0.75\n",
        "      max_area: 1.0\n",
        "      overlap_thresh: 0.0\n",
        "    }\n",
        "  }\n",
        "  sync_replicas: true\n",
        "  optimizer {\n",
        "    momentum_optimizer {\n",
        "      learning_rate {\n",
        "        cosine_decay_learning_rate {\n",
        "          learning_rate_base: 0.03999999910593033\n",
        "          total_steps: $training_steps\n",
        "          warmup_learning_rate: 0.013333000242710114\n",
        "          warmup_steps: $warmup_steps\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.8999999761581421\n",
        "    }\n",
        "    use_moving_average: false\n",
        "  }\n",
        "  fine_tune_checkpoint: \"/content/TensorFlow/workspace/training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
        "  num_steps: $training_steps #set the steps\n",
        "  startup_delay_steps: 0.0\n",
        "  replicas_to_aggregate: 8\n",
        "  max_number_of_boxes: 100\n",
        "  unpad_groundtruth_tensors: false\n",
        "  fine_tune_checkpoint_type: \"detection\"\n",
        "  use_bfloat16: false\n",
        "  fine_tune_checkpoint_version: V2\n",
        "}\n",
        "train_input_reader {\n",
        "  label_map_path: \"/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt\"\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/TensorFlow/workspace/training_demo/annotations/train.record\"\n",
        "  }\n",
        "}\n",
        "eval_config {\n",
        "  metrics_set: \"coco_detection_metrics\"\n",
        "  use_moving_averages: false\n",
        "}\n",
        "eval_input_reader {\n",
        "  label_map_path: \"/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_epochs: 1\n",
        "  tf_record_input_reader {\n",
        "    input_path: \"/content/TensorFlow/workspace/training_demo/annotations/test.record\"\n",
        "  }\n",
        "}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5pNweOQGqmGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training pipeline\n",
        "\n",
        "TRAINING_STEPS = 2000\n",
        "WARMUP_STEPS = 200\n",
        "PIPELINE_CONFIG_PATH='dataset/pipeline.config'\n",
        "\n",
        "pipeline = Template(config_file_template).substitute(\n",
        "    training_steps=TRAINING_STEPS, warmup_steps=WARMUP_STEPS)\n",
        "\n",
        "with open(\"/content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/pipeline.config\", 'w') as f:\n",
        "    f.write(pipeline)"
      ],
      "metadata": {
        "id": "09dzKBcPrcIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # pipeline.config changes\n",
        "\n",
        "# 3 : 3\n",
        "# 131 8\n",
        "# 161: \"/content/TensorFlow/workspace/training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
        "# 167: 'detection'\n",
        "# 168: false\n",
        "# 172: \"/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt\"\n",
        "# 174: \"/content/TensorFlow/workspace/training_demo/annotations/train.record\"\n",
        "# 182: \"/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt\"\n",
        "# 186: \"/content/TensorFlow/workspace/training_demo/annotations/test.record\""
      ],
      "metadata": {
        "id": "8TLqSxJD66cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/TensorFlow/models/research/object_detection/model_main_tf2.py /content/TensorFlow/workspace/training_demo"
      ],
      "metadata": {
        "id": "zpzL8HGkVXYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TensorFlow/workspace/training_demo"
      ],
      "metadata": {
        "id": "Mk7_YDmRVmW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ],
      "metadata": {
        "id": "LiZSrFoU42V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.1.2.30"
      ],
      "metadata": {
        "id": "K0I9igCM43AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/TensorFlow/models/research/object_detection/model_main_tf2.py /content/TensorFlow/workspace/training_demo"
      ],
      "metadata": {
        "id": "OLc3jT866-BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/TensorFlow/workspace/training_demo"
      ],
      "metadata": {
        "id": "1i2UuWSG7AF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_record_path = '/content/TensorFlow/workspace/training_demo/annotations/train.record'\n",
        "test_record_path = '/content/TensorFlow/workspace/training_demo/annotations/train.record'\n",
        "model_dir = '/content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn'\n",
        "labelmap_path = '/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt'\n",
        "\n",
        "pipeline_config_path = '/content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/pipeline.config'\n",
        "fine_tune_checkpoint = '/content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/ckpt-1'"
      ],
      "metadata": {
        "id": "dEQA2NFa7I2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config"
      ],
      "metadata": {
        "id": "xLz5rkp6Vn2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation on test dataset**"
      ],
      "metadata": {
        "id": "sUeSspL776Fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_config_path} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --checkpoint_dir={model_dir} "
      ],
      "metadata": {
        "id": "dNnkJ_Qf6zHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/'"
      ],
      "metadata": {
        "id": "scZl1jxB8FOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/TensorFlow/models/research/object_detection/exporter_main_v2.py /content/TensorFlow/workspace/training_demo"
      ],
      "metadata": {
        "id": "7_CoGYXaRpOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn/pipeline.config --trained_checkpoint_dir /content/TensorFlow/workspace/training_demo/models/my_ssd_resnet50_v1_fpn --output_directory trained-inference-graphs/output\n"
      ],
      "metadata": {
        "id": "7Z72E4xPSGTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "3J-j5MpAS1fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "test_images = glob('/content/TensorFlow/workspace/training_demo/images/test/*.jpg')\n",
        "test_images[:5]"
      ],
      "metadata": {
        "id": "sCF2_rDGe7N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os \n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "PATH_TO_MODEL_DIR = \"/content/TensorFlow/workspace/training_demo/trained-inference-graphs/output\"\n",
        "\n",
        "PATH_TO_CFG = PATH_TO_MODEL_DIR + \"/pipeline.config\"\n",
        "PATH_TO_CKPT = PATH_TO_MODEL_DIR + \"/checkpoint\"\n",
        "\n",
        "print('Loading model... ', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
        "model_config = configs['model']\n",
        "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-0')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    \"\"\"Detect objects in image.\"\"\"\n",
        "\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "    return detections\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))"
      ],
      "metadata": {
        "id": "vWtMKHMzYLIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS = \"/content/TensorFlow/workspace/training_demo/annotations/mscoco_label_map.pbtxt\"\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
        "                                                                    use_display_name=True)"
      ],
      "metadata": {
        "id": "yyBJeojScUPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "for image_path in test_images[:3]:\n",
        "\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # All outputs are batches tensors.\n",
        "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "    # We're only interested in the first num_detections.\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=200,\n",
        "            min_score_thresh=.30,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(image_np_with_detections)\n",
        "    print('Done')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sN3FvsvbeK8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nms(rects, thd=0.5):\n",
        "    \"\"\"\n",
        "    Filter rectangles\n",
        "    rects is array of oblects ([x1,y1,x2,y2], confidence, class)\n",
        "    thd - intersection threshold (intersection divides min square of rectange)\n",
        "    \"\"\"\n",
        "    out = []\n",
        "\n",
        "    remove = [False] * len(rects)\n",
        "\n",
        "    for i in range(0, len(rects) - 1):\n",
        "        if remove[i]:\n",
        "            continue\n",
        "        inter = [0.0] * len(rects)\n",
        "        for j in range(i, len(rects)):\n",
        "            if remove[j]:\n",
        "                continue\n",
        "            inter[j] = intersection(rects[i][0], rects[j][0]) / min(square(rects[i][0]), square(rects[j][0]))\n",
        "\n",
        "        max_prob = 0.0\n",
        "        max_idx = 0\n",
        "        for k in range(i, len(rects)):\n",
        "            if inter[k] >= thd:\n",
        "                if rects[k][1] > max_prob:\n",
        "                    max_prob = rects[k][1]\n",
        "                    max_idx = k\n",
        "\n",
        "        for k in range(i, len(rects)):\n",
        "            if (inter[k] >= thd) & (k != max_idx):\n",
        "                remove[k] = True\n",
        "\n",
        "    for k in range(0, len(rects)):\n",
        "        if not remove[k]:\n",
        "            out.append(rects[k])\n",
        "\n",
        "    boxes = [box[0] for box in out]\n",
        "    scores = [score[1] for score in out]\n",
        "    classes = [cls[2] for cls in out]\n",
        "    return boxes, scores, classes\n",
        "\n",
        "\n",
        "def intersection(rect1, rect2):\n",
        "    \"\"\"\n",
        "    Calculates square of intersection of two rectangles\n",
        "    rect: list with coords of top-right and left-boom corners [x1,y1,x2,y2]\n",
        "    return: square of intersection\n",
        "    \"\"\"\n",
        "    x_overlap = max(0, min(rect1[2], rect2[2]) - max(rect1[0], rect2[0]));\n",
        "    y_overlap = max(0, min(rect1[3], rect2[3]) - max(rect1[1], rect2[1]));\n",
        "    overlapArea = x_overlap * y_overlap;\n",
        "    return overlapArea\n",
        "\n",
        "\n",
        "def square(rect):\n",
        "    \"\"\"\n",
        "    Calculates square of rectangle\n",
        "    \"\"\"\n",
        "    return abs(rect[2] - rect[0]) * abs(rect[3] - rect[1])"
      ],
      "metadata": {
        "id": "D30x8ZqZiCKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference_as_raw_output(path2images,\n",
        "                            box_th = 0.25,\n",
        "                            nms_th = 0.5,\n",
        "                            to_file = False,\n",
        "                            data = None,\n",
        "                            path2dir = False):\n",
        "  print (f'Current data set is {data}')\n",
        "  \"\"\"\n",
        "  Function that performs inference and return filtered predictions\n",
        "  \n",
        "  Args:\n",
        "    path2images: an array with pathes to images\n",
        "    box_th: (float) value that defines threshold for model prediction. Consider 0.25 as a value.\n",
        "    nms_th: (float) value that defines threshold for non-maximum suppression. Consider 0.5 as a value.\n",
        "    to_file: (boolean). When passed as True => results are saved into a file. Writing format is\n",
        "    path2image + (x1abs, y1abs, x2abs, y2abs, score, conf) for box in boxes\n",
        "    data: (str) name of the dataset you passed in (e.g. test/validation)\n",
        "    path2dir: (str). Should be passed if path2images has only basenames. If full pathes provided => set False.\n",
        "    \n",
        "  Returs:\n",
        "    detections (dict): filtered predictions that model made\n",
        "  \"\"\"\n",
        "  print (f'Current data set is {data}')\n",
        "  print (f'Ready to start inference on {len(path2images)} images!')\n",
        "  \n",
        "  for image_path in tqdm(path2images):\n",
        "      \n",
        "      if path2dir: # if a path to a directory where images are stored was passed in\n",
        "          image_path = os.path.join(path2dir, image_path.strip())\n",
        "          \n",
        "      image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "      input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "      detections = detect_fn(input_tensor)\n",
        "      \n",
        "      # checking how many detections we got\n",
        "      num_detections = int(detections.pop('num_detections'))\n",
        "      \n",
        "      # filtering out detection in order to get only the one that are indeed detections\n",
        "      detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
        "      \n",
        "      # detection_classes should be ints.\n",
        "      detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "      \n",
        "      # defining what we need from the resulting detection dict that we got from model output\n",
        "      key_of_interest = ['detection_classes', 'detection_boxes', 'detection_scores']\n",
        "      \n",
        "      # filtering out detection dict in order to get only boxes, classes and scores\n",
        "      detections = {key: value for key, value in detections.items() if key in key_of_interest}\n",
        "      \n",
        "      if box_th: # filtering detection if a confidence threshold for boxes was given as a parameter\n",
        "          for key in key_of_interest:\n",
        "              scores = detections['detection_scores']\n",
        "              current_array = detections[key]\n",
        "              filtered_current_array = current_array[scores > box_th]\n",
        "              detections[key] = filtered_current_array\n",
        "      \n",
        "      if nms_th: # filtering rectangles if nms threshold was passed in as a parameter\n",
        "          # creating a zip object that will contain model output info as\n",
        "          output_info = list(zip(detections['detection_boxes'],\n",
        "                                  detections['detection_scores'],\n",
        "                                  detections['detection_classes']\n",
        "                                )\n",
        "                            )\n",
        "          boxes, scores, classes = nms(output_info)\n",
        "          \n",
        "          detections['detection_boxes'] = boxes # format: [y1, x1, y2, x2]\n",
        "          detections['detection_scores'] = scores\n",
        "          detections['detection_classes'] = classes\n",
        "          \n",
        "      if to_file and data: # if saving to txt file was requested\n",
        "\n",
        "          image_h, image_w, _ = image_np.shape\n",
        "          file_name = f'pred_result_{data}.txt'\n",
        "          \n",
        "          line2write = list()\n",
        "          line2write.append(os.path.basename(image_path))\n",
        "          \n",
        "          with open(file_name, 'a+') as text_file:\n",
        "              # iterating over boxes\n",
        "              for b, s, c in zip(boxes, scores, classes):\n",
        "                  \n",
        "                  y1abs, x1abs = b[0] * image_h, b[1] * image_w\n",
        "                  y2abs, x2abs = b[2] * image_h, b[3] * image_w\n",
        "                  \n",
        "                  list2append = [x1abs, y1abs, x2abs, y2abs, s, c]\n",
        "                  line2append = ','.join([str(item) for item in list2append])\n",
        "                  \n",
        "                  line2write.append(line2append)\n",
        "              \n",
        "              line2write = ' '.join(line2write)\n",
        "              text_file.write(line2write + os.linesep)\n",
        "      \n",
        "      return detections"
      ],
      "metadata": {
        "id": "V5vQ31W2jMxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://app.neptune.ai/anton-morgunov/tf-test/n/model-for-inference-36c9b0c4-8d20-4d5a-aa54-5240cc8ce764/6f67c0e3-283c-45de-ae56-405aecd736c0"
      ],
      "metadata": {
        "id": "V_TRdRC0jT0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of tfod2-setup",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
